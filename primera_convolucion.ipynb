{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/jortegon/Aprendizaje-Profundo/blob/main/primera_convolucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Importar el conjunto de datos Fashion MNIST\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalizar los valores de píxeles de las imágenes dividiéndolos por 255.0\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Definir el modelo secuencial\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),  # Capa de aplanamiento para convertir las imágenes en un vector 1D\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),  # Capa densa con 128 unidades y función de activación ReLU\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)  # Capa de salida con 10 unidades y función de activación Softmax\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Imprimir la versión de TensorFlow\n",
    "print(tf.__version__)\n",
    "\n",
    "# Importar el conjunto de datos Fashion MNIST\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reorganizar los datos de entrenamiento y prueba para que tengan una dimensión adicional para el canal de color\n",
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "\n",
    "# Normalizar los valores de píxeles de las imágenes dividiéndolos por 255.0\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Definir el modelo secuencial\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((28, 28, 1)),  # Capa de entrada con la forma de las imágenes\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),  # Capa de convolución con 64 filtros y función de activación ReLU\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Capa de pooling para reducir la dimensionalidad\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),  # Capa de convolución adicional\n",
    "    tf.keras.layers.MaxPooling2D(2,2),  # Capa de pooling adicional\n",
    "    tf.keras.layers.Flatten(),  # Capa de aplanamiento para convertir las imágenes en un vector 1D\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Capa densa con 128 unidades y función de activación ReLU\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Capa de salida con 10 unidades y función de activación Softmax\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Imprimir un resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear una figura y subfiguras\n",
    "f, axarr = plt.subplots(3, 4)\n",
    "\n",
    "# Definir los índices de las imágenes a visualizar y el número de convolución\n",
    "FIRST_IMAGE = 0\n",
    "SECOND_IMAGE = 7\n",
    "THIRD_IMAGE = 26\n",
    "CONVOLUTION_NUMBER = 1\n",
    "\n",
    "# Crear un modelo de activación para visualizar las salidas de cada capa\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs=model.inputs, outputs=layer_outputs)\n",
    "\n",
    "# Iterar sobre las subfiguras y visualizar las salidas de la capa de convolución\n",
    "for x in range(0, 4):\n",
    "    # Obtener la salida de la capa de convolución para la primera imagen\n",
    "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[0, x].imshow(f1[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[0, x].grid(False)\n",
    "    \n",
    "    # Obtener la salida de la capa de convolución para la segunda imagen\n",
    "    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[1, x].imshow(f2[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[1, x].grid(False)\n",
    "    \n",
    "    # Obtener la salida de la capa de convolución para la tercera imagen\n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2, x].imshow(f3[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2, x].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actividades complementarias:\n",
    "\n",
    "* Intenta editar las convoluciones. Cambia los 32 por 16 o 64. ¿Qué impacto tendrá esto en la precisión y/o el tiempo de entrenamiento?\n",
    "\n",
    "* Elimina la convolución final. ¿Qué impacto tendrá esto en la precisión o el tiempo de entrenamiento?\n",
    "\n",
    "* ¿Qué pasa si agregas más convoluciones? ¿Qué impacto crees que esto tendrá? Experimenta con ello.\n",
    "\n",
    "* Elimina todas las convoluciones excepto la primera. ¿Qué impacto crees que esto tendrá? Experimenta con ello.\n",
    "\n",
    "* Es posible implementar un callback para verificar la función de pérdida y cancelar el entrenamiento una vez que alcanzara un cierto valor. ¡Intenta implementarlo aquí!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Imprimir la versión de TensorFlow\n",
    "print(tf.__version__)\n",
    "\n",
    "# Importar el conjunto de datos MNIST\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reorganizar los datos de entrenamiento y prueba para que tengan una dimensión adicional para el canal de color\n",
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "\n",
    "# Normalizar los valores de píxeles de las imágenes dividiéndolos por 255.0\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Definir el modelo secuencial\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),  # Capa de convolución con 32 filtros y función de activación ReLU\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Capa de pooling para reducir la dimensionalidad\n",
    "    tf.keras.layers.Flatten(),  # Capa de aplanamiento para convertir las imágenes en un vector 1D\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Capa densa con 128 unidades y función de activación ReLU\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Capa de salida con 10 unidades y función de activación Softmax\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "# Imprimir la precisión del modelo en el conjunto de prueba\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
